% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/binom_blasso.R
\name{binom_blasso}
\alias{binom_blasso}
\title{Bootstrap Validation for Binomial Lasso Regression}
\usage{
binom_blasso(
  x,
  y,
  loops = 2,
  bootstrap = TRUE,
  alpha = 1,
  nfolds = 10,
  seed = 987654321,
  ncores = 2
)
}
\arguments{
\item{x}{x matrix as in glmnet.}

\item{y}{Should be either a factor with two levels.}

\item{loops}{Number of loops (a \code{glmnet::cv.glmnet} model will be performed in each loop).}

\item{bootstrap}{Logical indicating if bootstrap will be performed or not.}

\item{alpha}{The elasticnet mixing parameter, with 0 ≤ alpha ≤ 1. alpha = 1 is the lasso penalty, and alpha = 0 the ridge penalty.}

\item{nfolds}{number of folds - default is 10. Although nfolds can be as large as the sample size (leave-one-out CV), it is not recommended for large datasets. Smallest value allowable is nfolds=3.}

\item{seed}{\code{set.seed()} that will be used.}

\item{ncores}{Number of cores. Each loop will run in one core using the \code{foreach} package.}
}
\value{
A LassoLoop object with the results.
}
\description{
This function performs n \code{glmnet::cv.glmnet(family = "binomial")} models using bootstrap validation and splitting the input data in train and test at each loop.
}
\references{
Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization Paths for Generalized Linear Models via Coordinate Descent. Journal of Statistical Software, 33(1), 1-22. URL http://www.jstatsoft.org/v33/i01/.
}
\author{
Pol Castellano-Escuder
}
